# 1.嵌入、潜空间和表征
## 1.1 嵌入
- 嵌入向量简称嵌入，能够将高维数据编码为低维向量
	- 独热编码：是一种将非类数据表征为二进制向量的编码方式，每个类别对应一个向量，该向量在分类索引对应的位置为1，其余位置取值为0，确保分类取值的表征形式可以被一些机器学习算法处理
	- 嵌入向量的维数可以比原始输入的维数更高，也可以更低，通过嵌入方法，可以将输入数据更极致的编码为二维码连续稠密向量的表征形式，用于可视化展示和聚类分析
## 1.2 潜空间
- 即嵌入空间同义，即嵌入向量被映射到的空间
	- 视为包含特征的任意特征空间，通常是输入特征的压缩版本
## 1.3 表征
- 输入的一种编码方式，通常是输入的中间形态

# 2.自监督学习
是一种预训练过程，能够让神经网络以监督学习的方式学习大规模无标签数据集
## 2.1自监督学习与迁移学习
- 迁移学习是先在一种任务上预训练模型，然后将预训练好的模型作为训练起点，然后再应用于第二种任务继续训练
   ![[Pasted image 20250726001553.png]]
- 自监督学习在无标签数据而非有变迁数据上进行模型的预训练，无标签数据集只能基于数据本身的结构想办法生成标签，自监督训练任务也被称为代理任务
- 迁移学习和自监督学习核心区别是如何获取标签
## 2.2自预测与对比自监督学习
- 自预测 通常会更改或掩蔽一部分内容，并训练模型来重建原始输入数据
   ![[Pasted image 20250726001449.png]]
   训练神经网络所产生的其嵌入向量，能够使得相似训练样本之间的向量距离最小化，不相似样本之间的向量距离最大化
   ![[Pasted image 20250726001347.png]]
# 3.小样本学习
小样本学习是一种监督学习方法，适用于训练集较小且每个标签的样本量都非常有限的情况
## 3.1数据集和术语
- 模型拟合训练数据集，并在测试数据集上对模型进行评测
- 小样本学习不是直接使用训练数据集，而是使用所谓支撑集
- 模型会从支撑集中抽样而成的训练任务上进行训练，每次训练任务完成，称之为一个回合
- 训练中遇到的标签被称为基类，支撑集通常被称为基集
- 元学习本质就是通过更新模型的参数，以便模型能够更好的适应新任务
# 4.彩票假设
## 4.1 彩票假设的训练过程

![[Pasted image 20250726002726.png]]
- 对单个权重剪枝称为非结构化剪枝
- 对网络总较大的块剪枝，比如整个卷集滤波通道，称为结构化剪枝
## 4.2实际意义和局限性

当目前为止，仍没有办法在不训练原始网络的情况下找到这些中奖彩票，如果算上剪枝步骤，这个训练过程甚至可能比常规成本还高

# 5.利用数据来减少过拟合现象
模型对训练数据拟合过于紧密，导致学习到了数据的噪声和异常值，而非数据背后真实的规律，结果就是在训练数据上表现良好，但是在未见过的数据或测试数据上表现不佳
## 5.1 常用方法
- 采集更多的数据：模型在训练集和验证集上表现的差距，反映过拟合程度---差距越大，说明过拟合越严重
- 数据增强：基于现有的数据生成新的数据样本或特征，它能在不采集额外数据的情况下扩充数据集
- 预训练
- 特征工程和标准化
- 加入对抗样本和标签或特征噪声
- 标签平滑
- 更小的训练批次
# 6.通过改进模型减少过拟合现象
