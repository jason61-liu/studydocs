### 模型遗忘问题如何解决
- 数据层面：混合原始任务与新任务，数据混合策略，进行混合训练
- 训练策略：正则化约束/学习率控制/渐进式学习，冻结关键神经元权重，采用余弦退火策略
- 模型架构：多任务学习/Adapter模块/模型融合
- 评估监控：新旧任务指标同步验证，动态评估机制，设置平衡次数，增强原始数据权重，增加训练时间
### 多头自注意力机制
- 允许模型关注不同位置信息，从多个子空间捕获不同的特征
- 分头策略实现
- 矩阵变换实现
- 多视角特征捕捉：不同头侧重点关注特征不同
- 融合与正则化， 
- 工程优化flash attention
- 稀疏注意力，特征解耦，计算并行，灵活扩展，可解释路径
### RAG流程
- 检索增强生成，结合检索和生成两种技术，用于提升模型生成回答质量，特别需要外部知识的时候
- 用户输入处理-文档检索-文档处理-信息整合-生成回答-后处理
- 三个主要阶段：
	- 检索阶段
	- 增强阶段
	- 生成阶段

### 大模型微调流程
- 针对特定任务或领域进一步训练，使模型适应新的任务，如下步骤：
	- 确定任务和目标
	- 准备数据
	- 数据预处理
	- 选择预训练模型
	- 调整模型结构
	- 设置训练参数
	- 训练过程
	- 评估与验证
	- 部署与应用
### 模型微调评估效果
- 明确评估目标
- 技术指标评估
- 业务场景适配性：准确性，是否存在幻觉
- 效率与稳定性：效果，时延
	- 推理速度
	- 资源占用
	- 输出稳定性
- 长期监控和迭代：可观测性，roadmap
	- 在线指标监控
	- 数据漂移检测

### 超长文本进行微调训练
- 模型架构的改进：稀疏注意力机制，分块策略，
	- 稀疏注意力机制
	- 位置编码拓展，长度外推，让模型适应更长的文本
	- 
- 微调具体策略：Rope ALibi等相对位置编码
	- 分块与长文本保留，确保上下文连贯
	- 层次化处理
- 训练技巧与资源优化
	- 渐进式训练
	- 参数高效微调：lora，adapter
	- 显存优化技术：梯度检查点，混合精度训练，模型并行
- 任务驱动的微调策略
	- 注意力增强
	- 长文本目标函数设计
-评估与挑战
	-  评估指标
	- 信息碎片化
	- 显存限制
	- 位置外推
### 大模型应用保证实时性和多轮对话一致性
- 实时性优化
	- 模型优化：对模型进行蒸馏（知识蒸馏），保持性能的同时减小模型大小，从而加快推理速度；硬件加速；动态批处理
	- 缓存机制
	- 异步处理
	- 硬件加速
	- 响应分块
- 多轮会话一致性
	- 上下文管理：上下文窗口优化
	- 对话状态跟踪：维护一个对话状态机或上下文缓存
	- 显示确认和澄清
	- 模型微调：针对多轮对话任务对模型进行微调
	- 分块处理：将长对话分成多个片段

### 保证到模型生成内容的合规性
	- 技术层面：模型训练与部署关键控制，数据清晰和预过滤；RLHF；合规性微调；实时内容过滤；输出处概率阈值控制
	- 流程层面：构建审核闭环；多级审核机制；可解释性工具；版本灰度发布
	- 制度层面：合规体系搭建；法规 映射；权限分级控制；日志溯源与问责；第三方审计
	- 前沿技术补充：宪法式AI；数字水印

### 大模型实现多模态任务
- 处理多种类型数据，如文本，图像，音频，视频
- 图文问答，视频摘要
- 统一编码器
- 模态适配器
- 预训练-微调范式  
### 过拟合和欠拟合
- 过拟合：模型在训练数据表现极佳，但新数据集表现显著下降，过度训练导致，导致泛化能力比较差
	- 模型复杂度过高
	- 训练数据不足或噪声多
	- 训练时间过长
	- 特征冗余或无关特征过多
---
		- 增加数据量
		- 降低模型复杂度
		- 正则化技术
		- 早停法
		- 交叉验证
- 欠拟合：模型在训练和测试数据上表现不佳，无法捕捉数据中基本模式，模型过于简单或训练不足导致
	- 模型复杂度过低
	- 特征不足或缺乏代表性
	- 训练不充分
---
	- 增加模型复杂度
	- 特征工程
	- 减少正则化强度
	- 延长训练时间

### 全参数微调，lora，qlora区别
- 全参数微调：调整预训练大模型所有参数，使其适应下游任务
	- 资源需求：显存占用高，需要大量微调以避免过拟合
	- 效果：性能上限高，适合复杂任务；容易出现灾难性遗忘
- Lora：冻结元参数，旁路添加可训练低秩AB矩阵
	- 显存：新增参数量低
	- 训练速度快：更快，支持多任务匹配
	- 性能接近全参数微调，稳定性高，扩展性强
- QLora：引入量化技术 Lora+4bit量化源模型
	- 显存：节省资源
	- 计算代价：反量化操作增加训练时间
	- 效果：低显存下
### 模型蒸馏和模型量化
- 模型蒸馏：知识迁移为核心，牺牲少量精度换取模型轻量化
	- 将大型复杂模型的知识迁移到轻量的小模型，小模型模仿大模型的输出分布和中间特征
	- 软标签
	- 温度参数
	- 损失函数设计：软标签损失kl和原始标签交叉熵损失
	- 模型体积压缩至30M，推理速速提升5倍，准确率损失2%，满足业务需求
- 模型量化：降低计算精度提升效率，适合对延迟敏感场景
	- 将模型权重或激活值从高精度FP32转换为低精度INT8，降低计算和存储开销
	- 动态范围校准
	- 量化感知训练
	- 后训练量化
### vllm推理加速如何实现
- 内存优化 pageAttention，按需动态分配
- 连续批处理 continuous Batching，实时监控请求状态，动态处理请求，迭代级调度；抢占式推理
- 内存池：预先申请大块内存，避免频繁分配
- 吞吐量；平均延迟；GPU利用率
- ~~swap_space 参数，将部分kv缓存卸载到cpu内存~~
### 解决大模型幻觉问题
- 模型生成不准确或虚构信息，看似合理但不符合事实，过拟合，存在噪声，缺乏领域知识
- 事实性幻觉：RAG解决，知识增强
- 逻辑性幻觉：添加规则引擎校验
- 指令跟随偏差：强化STF数据指令对齐
