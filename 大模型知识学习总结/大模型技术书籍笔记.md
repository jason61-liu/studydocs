## aibrix
当前大模型部署使用面对问题
1. 如何自动扩缩容
2. 异构gpu统一调度
3. lora 适配路由
4. prefix-aware-routing
---
n-grams：具有泛化能力
- n的选择会影响n-grams模型的泛化性能和计算复杂度
- 该语言模型是在n阶马尔可夫假设下，对语料库中出现的长度n词序列出现概率的极大自然估计
- 输入法，拼写纠错，机器翻译等任务广泛应用
- 缺点：观测长度有限，无法捕捉长程度依赖；泛化能力不足，逐字匹配，不能适应语言的复杂性
- 统计侧重于设计一个模型描摹已知
机器学习：
- 要素：训练数据，假设勒，归纳偏置，学习算法，学习范式
- 过程：在某种学习范式，基于训练数据，利用学习算法，从受归纳偏置的假设中选取出可以达到学习目标的假设，该假设可以泛化到未知数据上
- 训练数据：数量和质量
- 损失函数：用以衡量模型在对应样本上的错误程度，在训练集上的记过的加权和称为训练损失
- 学习算法：对损失进行优化，1阶优化和0阶优化
- 目的：在于减小泛化误差即真实误差
- 泛化误差：训练误差； 泛化误差界（数学期望）
- 概率近似正确（Probably Approximately Correct,PAC）：为机器学习提供了对机器学习方法进行定量分析的理论框架
	- 思想：当样本符合一定条件时，机器学习模型可以以一定概率达到近似正确
	- 没有放之四海而皆准的机器学习方法，总存在一个场景，让一个机器学习方法表现不佳
- 统计学习时代-->表征学习时代-->再到大模型时代
RNN：循环神经网络
- 不记忆历史输入
- 有记忆历史输入
- 历史状态以隐变量的形势循环叠加到当前状态，呈现出螺旋式前进的模式
- 涉及矩阵联乘操作，容易引起梯度消失或梯度爆炸，因此带有门控机制的LSTM提出，遗忘门，输入门，输出门
---
经验知识，学习载体，常识，学习方法，学习目标
- 层正则化：用以加速神经网络训练过程并取得更好的泛化性能，引入残差连接解决梯度消失问题
- 自回归：
	- 问题：错误级联放大和效率很低
	- 解决问题：Teacher Forcing方式，训练模型的过程和模型在推理过程存在差异，容易导致模型幻觉的问题
- 语言模型的采样
	- 概率最大化方法：贪心搜索法；波束搜索法
	- 随机采样方法：选出一组可能性高的候选词，然后按照其概率分布进行随机采样。top-k：方差过大或者过小，都存在问题；top-p：
	- Temperature机制
- 语言模型评测：
	- 内在评测：不依赖具体任务；困惑度 度量语言模型对测试文本感到困惑的程度，困惑度减小也意味着熵减
	- 外在评测：依赖具体任务，基于统计指标的评测BLEU和基于语言模型的评测
	- 基于上下文词嵌入：BERTScore，从精度，召回和F1量度当个方面对生成文档进行评测
	- 基于生成模型的评测：
- encode-only架构：情感识别判别任务；双向编码模型中全面注意力机制，只专注于判别任务，难以应对生成式任务
	- BERT： 与transformer结构相同，只是规模不同，掩码语言建模和上下文预测两种任务来学习生成上下文嵌入
	- RoBERTa：使用更大训练数据集，更长训练时间，更细致的学习任务和超参数调整来优化预训练过程，移除了BERT中的下文预测任务，采用动态掩码建模从而增强模型训练的多样性，帮助模型学习到更丰富的上下文信息，训练成本更大
	- ALBERT：参数主要来源词嵌入矩阵Embedding,采用参数因子分解方式；采用跨层参数共享方式减少其参数量，模型参数量小，训练速度快；在某些特定任务效果不佳
- encode-decode：造成训练成本增加
	- BART：token级别掩码
	- T5：span级别掩码，利用prompt工程技术直接适配到多种下游任务
- decode-only：适用于生成任务如对话
	- 开放式生成任务中，输入序列通常较简单或者不明确，无需维持一个完整的编码器来处理这些输入并不是必要的，因此简化的架构设计和强度的扩展性
	- 模型的轻量化
	- 更强的可扩展性
	- GPT
		- 上下文学习能力，RHLF
		- 模型规模与预训练语料同步提升
	- LLMA
		- 模型规模上保持相对稳定，专注于提升预训练数据的规模和质量
		- 拒绝采样
		- 分组查询注意力GQA
----
Transformer：
- 构建灵活，易并行，易拓展
- 并行输入，输入长度有限，模型规模随输入序列上度平方增长
RNN：
- 理论上可以处理无限长序列
- 容易出现梯度消失或爆炸，输入过度压缩，模型能力受限
Mamaba：状态空间模型加入选择机制，确保可以高效处理长序列，可以达到Transforme匹敌的模型能力
- 选择状态空间模型
---
上下文学习：构造特定Prompt，来使得语言模型理解并学习下游任务，不需要更新模型参数可以快速适应下游任务
- 零样本上下文学习
- 单样本上下文学习
- 少样本上下文学习
演示示例选择依据：相似性和多样性；
- 直接检索：代表KATE
- 聚类检索：划分为簇，代表Self-Prompting
- 迭代检索：依赖当前的问题和已选示例，代表 RetICL
影响因素：
- 预训练数据：领域丰富度，任务多样性，训练数据的分布特性
- 预训练模型：模型参数规模
- 演示示例：错误的输入-标签映射对模型有影响；数量和顺序同样影响上下文学习性能的关键因素
---
思维链
- system-1问题 常识问答，情感分类，意图识别等，随规模变大，大模型性能显著提升
- system-2问题 复杂数学计算，逻辑推理等，大模型性能提升缓慢甚至停滞不前
- 在提示中嵌入一系列中间推理步骤，提升模型system-2问题能力
- 思维树TOT：拆解-衍生-评估-搜索
- Self-Consistency：引入多样性的推理路径并从中选择最一致的答案，从而提高模型的推理准确性，不依赖于特定CoT形式，可以与其他CoT方法 兼容，共同作用于模型推理过程
	- 步骤：推理路径生成-汇总答案-选择答案
	- 利用大模型自身做选择一致性答案
---
参数微调：
- 上下文学习：能够模仿示例内容完成任务
	- 性能有限
	- 人力成本高
	- 推理效率低
- 指令微调(Instruct):对模型进行任务指令学习，使其能更好的理解和执行各种自然语言处理任务
	- 指令数据集：数据集成；大语言模型生成
- 监督微调SFT：基于构造的指令数据集，对大模型进行监督微调，通常以自回归方式进行训练
- 全量监督微调：需要更新所有参数，会消耗大量存储和计算资源；GPU内存不足；全量微调效率低
- PERT技术：如LoRA
	- 计算效率高：减少了需要更新参数数量，显著减少了训练时的计算资源
	- 存储效率高：保留部分微调参数，显著较低微调模型的存储空间
	- 适应性强：降低微调成本，保证微调性能不受影响，使模型可以快速适应不同任务，具有很好的灵活性
	- 三类方法：
		- 参数附加方法
			- 加在输入：prompt-tuning，可训练、连续嵌入；内存效率高，多任务能力，缩放特性
			- 加在模型：prefix-tuning-微调部分参数，提高参数效率，减少计算资源的需求；adapter-tuning-每个多头注意力层和全连接层后插入新的可学习神经网络模块来实现扩展，上投影层，非线性映射和一个下投影层的全连接模块；大幅度缩减微调参数量和计算量
			- 加在输出：黑盒模型，用户无法直接访问大语言模型，无法获取模型参数，代理微调，在一定程度上解决大规模语言模型微调和黑盒模型微调
		- 参数选择方法
			- 基于规则的方法：根据领域专家的知识和经验来指导模型的调整过程。BitFit：仅优化神经网络偏置项 Bias，仅在小规模模型；最后戏份之一层进行微调；最小绝对值的模型参数
			- 基于学习的方法：利用算法自动识别，模型训练过程总自动地选择可训练的参数子集；Child-tuning：通过梯度掩码矩阵策略实现仅对选中的子网络
			- 基于选择方法：通过选择性更新与训练模型的参数，在保持大部分不变
		- 低秩适配方法
			- 使用低秩矩阵近似原始权重更新矩阵；仅在低维子空间中进行参数更新，也能实现与完整参数更新类似的性能
			- LoRA：低秩适配，分解为两个小矩阵，冻结原始模型，仅微调这两个小矩阵；影响 因素：
				- 权重初始化方式；
				- 秩；较高秩表现更好
				- 施加位置
			- 内存占用：权重，激活，梯度，优化器，LoRA仅优化梯度和优化器内存
			- 优势：参数效率，插件化特性以及跨任务泛化
			- LoRA变体：依据：性能改进；任务泛化；训练改进；推理改进
			- AdaLoRA：不同模块和层中权重矩阵的重要性不同：将参数更新矩阵参数化为奇异值分解（SVD）的形式；再通过奇异值剪枝动态调整不同模块中LoRA的秩
			- LoRAHub：任务泛化，提供了一个可用的多LoRA组合的方法框架，讲已有任务上学习到LoRA插件进行组合，从而获得解决新任务的能力；包括组合和适应
			- QLoRA：模型量化，模型参数从高精度表示转化为低精度表示；可以显著减少存储，量化+反量化
			- S-LoRA：将输入LLM与LoRA参数的运算分离，两者分别计算完成之后再求和得到最终结果，只能应用于Attention阶段
	- 训练中应用：冻结大模型参数从而节省内存和计算的情况下，保持与全量训练相近的性能；具备插件化，任务特定，参数隔离的特点

---
模型编辑
- 针对特定知识点对模型进行编辑，其旨在修正大语言模型使其输出特定期望结果，同时不影响其他无关输出
- 如何精确控制模型编辑的范围时模型编辑的一个关键挑战
- 模型编辑性质归纳为五个方面：准确性；泛化性；可迁移性；局部性；高效性
- 外部扩展法：新的知识存储在附加外部参数或外部知识库中，将其和原始模型一起作为编辑后模型
	- 知识缓存法：编辑缓存；门控单元；推理模块；代表 SERAC
	- 附加参数法：将外部参数插入到模型的具体位置；代表 CALINET-在最后一个FFN层添加一个新的参数举证，将其称为校准FFN；T-Patcher-每个布丁独立训练，更适合连续编辑的场景
- 内部修改法：
	- 元学习：模型学习如何学习过程，通过多个任务上学习积累经验，也称为“元知识”，从而指导模型更高效的学习新任务
	- 定位编辑法：对原始模型的局部参数进行编辑，先定位到需要修改的参数的位置，然后修改关键参数 

---
RAG检索知识增强
- 幻觉问题：训练数据存在错误；模型本身对知识的掌握不足
- 知识过时：训练数据的滞后性，知识可能在模型训练后又发生了更新，导致模型内部知识过时
- 知识边界：训练数据的有限性，无法覆盖所有知识，知识在训练数据采集后仍回不断新增
- 知识偏差：训练数据中可能包含不实与偏见信息
- 对齐不当：偏好数据标注不当可能引入了不良偏好
- 知识长尾：部分信息出现频率低，导致模型对这些知识学习程度较低
- 曝光偏差：模型训练与推理任务存在差异，导致模型在实际推理时存在偏差，模型训练过程中采用Teaching force
- 解码偏差：模型解码策略中随机因素可能影响输出的准确性
---

- RAG分类： 黑盒模型和白盒模型
- 知识检索：
	- 知识构建：数据采集与预处理：数据清理；文本分块：固定大小分块；基于内容分块
- 知识增强：
	- 伪查询生成
	- 标题生成
- 查询语义增强：
	- 同义改写
	- 多视角分解
	- 背景文档生成
- 文本检索：
	- 检索质量：召回率，精度，多样性
	- 检索效率
	- 判别式检索器：稀疏检索器；双编码检索器；交叉编码检索器
	- 生成式检索器：直接将知识库中的文档记忆在模型参数总，接收到查询请求时，能够直接生成相关文档的标识符，以完成检索，内存效率高；生成速度快
	- 图检索器：有效识别内容之间的显著结构化关系
	- 向量数据库
	- 基于交叉编码的重排
- 生成增强
	- 内部支持可以解决的问题，不对该问题进行增强，判断大模型是否具有相关的内部知识来判断其是否需要增强
	- 外部观测法：流行度
	- 内部观测法：探针即线性分类器
	- 增强位置：输入端prompt增强，中间层增强，输出端增强
	- 多词迭代生强：对于复杂问题和模糊问题，分解式增强
- 降本增效：
	- 去除冗余信息：token级别；全文本级别方法；子文本级别的方法
	- 复用计算结果：RAGCache-KV张量缓存苦，缓存检索器和RAG控制器
应用场景：文本领域，多模态领域如医疗，Agent


