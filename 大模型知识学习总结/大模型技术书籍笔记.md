## aibrix
当前大模型部署使用面对问题
1. 如何自动扩缩容
2. 异构gpu统一调度
3. lora 适配路由
4. prefix-aware-routing
---
n-grams：具有泛化能力
- n的选择会影响n-grams模型的泛化性能和计算复杂度
- 该语言模型是在n阶马尔可夫假设下，对语料库中出现的长度n词序列出现概率的极大自然估计
- 输入法，拼写纠错，机器翻译等任务广泛应用
- 缺点：观测长度有限，无法捕捉长程度依赖；泛化能力不足，逐字匹配，不能适应语言的复杂性
- 统计侧重于设计一个模型描摹已知
机器学习：
- 要素：训练数据，假设勒，归纳偏置，学习算法，学习范式
- 过程：在某种学习范式，基于训练数据，利用学习算法，从受归纳偏置的假设中选取出可以达到学习目标的假设，该假设可以泛化到未知数据上
- 训练数据：数量和质量
- 损失函数：用以衡量模型在对应样本上的错误程度，在训练集上的记过的加权和称为训练损失
- 学习算法：对损失进行优化，1阶优化和0阶优化
- 目的：在于减小泛化误差即真实误差
- 泛化误差：训练误差； 泛化误差界（数学期望）
- 概率近似正确（Probably Approximately Correct,PAC）：为机器学习提供了对机器学习方法进行定量分析的理论框架
	- 思想：当样本符合一定条件时，机器学习模型可以以一定概率达到近似正确
	- 没有放之四海而皆准的机器学习方法，总存在一个场景，让一个机器学习方法表现不佳
- 统计学习时代-->表征学习时代-->再到大模型时代
RNN：循环神经网络
- 不记忆历史输入
- 有记忆历史输入
- 历史状态以隐变量的形势循环叠加到当前状态，呈现出螺旋式前进的模式
- 涉及矩阵联乘操作，容易引起梯度消失或梯度爆炸，因此带有门控机制的LSTM提出，遗忘门，输入门，输出门
---
经验知识，学习载体，常识，学习方法，学习目标
- 层正则化：用以加速神经网络训练过程并取得更好的泛化性能，引入残差连接解决梯度消失问题
- 自回归：
	- 问题：错误级联放大和效率很低
	- 解决问题：Teacher Forcing方式，训练模型的过程和模型在推理过程存在差异，容易导致模型幻觉的问题
- 语言模型的采样
	- 概率最大化方法：贪心搜索法；波束搜索法
	- 随机采样方法：选出一组可能性高的候选词，然后按照其概率分布进行随机采样。top-k：方差过大或者过小，都存在问题；top-p：
	- Temperature机制
- 语言模型评测：
	- 内在评测：不依赖具体任务；困惑度 度量语言模型对测试文本感到困惑的程度，困惑度减小也意味着熵减
	- 外在评测：依赖具体任务，基于统计指标的评测BLEU和基于语言模型的评测
	- 基于上下文词嵌入：BERTScore，从精度，召回和F1量度当个方面对生成文档进行评测
	- 基于生成模型的评测：
- encode-only架构：情感识别判别任务；双向编码模型中全面注意力机制，只专注于判别任务，难以应对生成式任务
	- BERT： 与transformer结构相同，只是规模不同，掩码语言建模和上下文预测两种任务来学习生成上下文嵌入
	- RoBERTa：使用更大训练数据集，更长训练时间，更细致的学习任务和超参数调整来优化预训练过程，移除了BERT中的下文预测任务，采用动态掩码建模从而增强模型训练的多样性，帮助模型学习到更丰富的上下文信息，训练成本更大
	- ALBERT：参数主要来源词嵌入矩阵Embedding,采用参数因子分解方式；采用跨层参数共享方式减少其参数量，模型参数量小，训练速度快；在某些特定任务效果不佳
- encode-decode：造成训练成本增加
	- BART：token级别掩码
	- T5：span级别掩码，利用prompt工程技术直接适配到多种下游任务
- decode-only：适用于生成任务如对话
	- 开放式生成任务中，输入序列通常较简单或者不明确，无需维持一个完整的编码器来处理这些输入并不是必要的，因此简化的架构设计和强度的扩展性
	- 模型的轻量化
	- 更强的可扩展性
	- GPT
		- 上下文学习能力，RHLF
		- 模型规模与预训练语料同步提升
	- LLMA
		- 模型规模上保持相对稳定，专注于提升预训练数据的规模和质量
		- 拒绝采样
		- 分组查询注意力GQA
----
Transformer：
- 构建灵活，易并行，易拓展
- 并行输入，输入长度有限，模型规模随输入序列上度平方增长
RNN：
- 理论上可以处理无限长序列
- 容易出现梯度消失或爆炸，输入过度压缩，模型能力受限
Mamaba：状态空间模型加入选择机制，确保可以高效处理长序列，可以达到Transforme匹敌的模型能力
- 选择状态空间模型
---
上下文学习：构造特定Prompt，来使得语言模型理解并学习下游任务，不需要更新模型参数可以快速适应下游任务
- 零样本上下文学习
- 单样本上下文学习
- 少样本上下文学习
演示示例选择依据：相似性和多样性；
- 直接检索：代表KATE
- 聚类检索：划分为簇，代表Self-Prompting
- 迭代检索：依赖当前的问题和已选示例，代表 RetICL
影响因素：
- 预训练数据：领域丰富度，任务多样性，训练数据的分布特性
- 预训练模型：模型参数规模
- 演示示例：错误的输入-标签映射对模型有影响；数量和顺序同样影响上下文学习性能的关键因素
---
思维链
- system-1问题 常识问答，情感分类，意图识别等，随规模变大，大模型性能显著提升
- system-2问题 复杂数学计算，逻辑推理等，大模型性能提升缓慢甚至停滞不前
- 在提示中嵌入一系列中间推理步骤，提升模型system-2问题能力
- 思维树TOT：拆解-衍生-评估-搜索
- Self-Consistency：引入多样性的推理路径并从中选择最一致的答案，从而提高模型的推理准确性，不依赖于特定CoT形式，可以与其他CoT方法 兼容，共同作用于模型推理过程
	- 步骤：推理路径生成-汇总答案-选择答案
	- 利用大模型自身做选择一致性答案
---
参数微调：
	


